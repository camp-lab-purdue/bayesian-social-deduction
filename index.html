<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="We introduce GRAIL, a novel agent for the social deduction game Avalon, which combines a graph-based belief inference model with a language model for interaction. GRAIL achieves a winrate of 67% against humans, and performs better than state-of-the-art reasoning models across all model sizes.">
  <meta property="og:title" content="Bayesian Social Deduction with Graph-Informed Language Models"/>
  <meta property="og:description" content="We introduce GRAIL, a novel agent for the social deduction game Avalon, which combines a graph-based belief inference model with a language model for interaction. GRAIL achieves a winrate of 67% against humans, and performs better than state-of-the-art reasoning models across all model sizes."/>
  <meta property="og:url" content="https://camp-lab-purdue.github.io/bayesian-social-deduction/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Bayesian Social Deduction with Graph-Informed Language Models">
  <meta name="twitter:description" content="We introduce GRAIL, a novel agent for the social deduction game Avalon, which combines a graph-based belief inference model with a language model for interaction. GRAIL achieves a winrate of 67% against humans, and performs better than state-of-the-art reasoning models across all model sizes.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/AvalonOverview.png">
  <meta name="twitter:card" content="GRAIL: Graph Reasoning Agent Informed through Language">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="GRAIL, Bayesian Social Deduction, Language Models, Avalon, Social Deduction Games, Social Reasoning, LRMs, Reasoning Models, AI Agents, LLMs, Deep Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Bayesian Social Deduction with Graph-Informed Language Models</title>
  <link rel="icon" type="image/png" href="static/images/favicon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Bayesian Social Deduction with Graph-Informed Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="" target="_blank">Shahab Rahimirad</a><sup>1</sup><sup>,*</sup>,</span>
                <span class="author-block">
                  <a href="https://guvengergerli.github.io" target="_blank">Guven Gergerli</a><sup>1</sup><sup>,*</sup>,</span>
                  <span class="author-block">
                    <a href="" target="_blank">Lucy Romero</a><sup>2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="" target="_blank">Angela Qian</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="" target="_blank">Matthew Lyle Olson</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://simonstepputtis.com" target="_blank">Simon Stepputtis</a><sup>4</sup><sup>,†</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://joe-campbell.github.io/website/" target="_blank">Joseph Campbell</a><sup>1</sup><sup>,†</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Purdue University, <sup>2</sup>University of Pittsburg, <sup>3</sup>Intel Labs, <sup>4</sup>Virginia Tech</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                    <span class="eql-cntrb"><small><sup>†</sup>Indicates Equal Advising</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="ComingSoon" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="ComingSoon" target="_blank"
                      class="external-link button is-normal is-rounded is-dark" disabled>
                      <span class="icon">
                        <i class="fas fa-database"></i>
                      </span>
                      <span>Dataset</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="ComingSoon" target="_blank"
                    class="external-link button is-normal is-rounded is-dark" disabled>
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="ComingSoon" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/SBBS.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        The agent playing Avalon and using Bayesian reasoning to deduce the roles of other players.
      </h2>
      <!-- <img src="static/images/AvalonOverview.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Overview
        </h2> -->
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Social reasoning -- inferring unobservable beliefs and intentions from partial observations of other agents -- remains a challenging task for large language models (LLMs). We evaluate the limits of current reasoning language models in the social deduction game Avalon and find that while the largest models demonstrate strong performance, they require extensive test-time inference and degrade sharply when distilled to smaller, real-time-capable variants. To address this, we introduce a hybrid reasoning framework that externalizes belief inference to a structured probabilistic model, while using an LLM for language understanding and interaction. Our approach achieves performance competitive with much larger models in agent-agent play and, notably, is the first language agent to defeat human players in a controlled study -- achieving a 67% win rate and receiving higher qualitative ratings than both reasoning baselines and human teammates. We release code, models, and a dataset to support future work on social reasoning in LLM agents.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Agent Description -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">GRAIL: Graph Reasoning Agent Informed through Language</h2>
      <div class="is-four-fifths">
        <img src="static/images/AvalonOverview.png" alt="The overview of the GRAIL agent within Avalon game"/>
        <h2 class="subtitle has-text-centered">
          Overview
        </h2>
      </div>
      <div class="content has-text-justified">
        <p>
          We introduce GRAIL, a novel agent for the social deduction game Avalon, which combines a graph-based belief inference model with a language model for interaction.
          GRAIL uses a Factor Graph to model the dependencies and conditional probabiltiy within the game state, and uses Max-Product Belief propagation to infer beliefs about the hidden roles of players. A neural network is used to estimate the conditional probabiltiy in factor functions.
          Furthermore, GRAIL uses an LLM to analyze the game messages and caluclate the prior probabilites of the roles. 
        </p>
      </div>
      <div class="content has-text-justified">
        <p>
          To show the importance of the components, we study the ablations of GRAIL by comparing it to versions that only use Beliefs with no prior from the LLM, and a verison which only uses the priors from the LLM and treats them as beliefs.
          We find that the combination of the two components is crucial for the agent's performance, and that the LLM is able to provide a strong prior for the beliefs.
        </p>
        <div class="centered is-four-fifths" style="width: 70%; margin: 0 auto;">
          <img src="./static/images/tables.png" alt="Tables demonstrating the winrates of GRAIL and other agnet types" style="width: 100%; display: block; margin: auto;">
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Agent Description -->



<!-- Reasoning result -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Is GRAIL better than Reasoning models?</h2>
      <div class="content has-text-justified">
        <p>
          We develop an agent that prompts the reasoning model DeepSeek-R1, and compare the performance of GRAIL to this agent. 
        </p>
      </div>
      <div class="columns is-centered">
        <!-- Belief Qs. -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">GRAIL is better across all model sizes</h3>
              <p>
                We compared the winrate of GRAIL and the reasoning model across model sizes. We also tried GRAIL with DeepSeek-R1 models and the reasoning model with non-reasoning LLMs. The results demonstrates that the GRAIL agent can achieve impressive winrates across model sizes while the same cannot be said for the reasoning agent.
              </p>
              <img src="./static/images/winrate_comparison_reasoning.png" alt="Comparision of the winrates of GRAIL and reasoning models">
          </div>
        </div>
        <!--/ Belief Qs. -->
  
        <!-- CoT and FT. -->
        <div class="column">
          <h3 class="title is-4">GRAIL hallucinates less than LRMs</h3>
          <div class="columns is-centered">
            <div class="column content">
              <p>
              We anallyzed the hallucination rates of GRAIL and the resaoning agent across different model sizes using an LLM-as-Judge scheme with 95% accuracy. Across all model sizes, our GRAIL agent achieves less hallucinations and the statements it makes in the game are more consistent with the game history and state.
              </p>
              <div class="centered is-four-fifths" style="width: 70%; margin: 0 auto;">
                <img src="./static/images/hallucination_rates_by_size.png" alt="Hallucination rates of GRAIL and reasoning agents across model sizes">
              </div>
            </div>
          </div>
        </div>
        <!--/ CoT and FT. -->
      </div>
    </div>
  </div>
</section>
<!-- Reasoning result -->


<!-- Human result -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Can GRAIL play against humans?</h2>
      <div class="content has-text-justified">
        <p>
          In human evaluations, we put three participants in a game with 3 agents. Two of the human participants constructed the Evil team, and the other human played alongside the agents in the Good team. We ran the experiments with both GRAIL agents and reasoning agents using GPT-o4-mini.<br>
          <b>Good teams with GRAIL win 67% of times against humans, while with reasoning agent they win only 27% of times
          </b>
        </p>
      </div>

      <div class="columns is-centered">
        <!-- Belief Qs. -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Do humans prefer GRAIL to LRMs?</h3>
              <p>
                After each game, the participants were asked to rate the players (both agnets and other humans) based on two criteria: 
                <ul>
                  <li>Q1: The player contributed to the success of the Good team in the game.</li>
                  <li>Q2: The player made halpful comments in the game</li>
                </ul> 
                The results show that the participants significantly preferred GRAIL to a reasoning agent.
              </p>
              <img src="./static/images/human_vote_comparison.png" alt="evaluation of human players">
          </div>
        </div>
        <!--/ Belief Qs. -->
  
        <!-- CoT and FT. -->
        <div class="column">
          <h3 class="title is-4">How good are LLM agents as Evil players?</h3>
          <div class="columns is-centered">
            <div class="column content">
              <!-- <p>
              todo
              </p>
              <img src="./static/images/perround_human.png" alt="todo"> -->
              <p>
                We record the beliefs of the agents about the roles of the players and plot their distribution. The result shows that against humans, the GRAIL agent has a difficult time detecting the Evil players with a high certainity. This is in contrast to the games agains other agents which result in a high certainity about the player roles. For more in detail exploration of these results, please refer tot the paper.
                </p>
                <img src="./static/images/belief_violins_5-Round_Games_human_2.png" alt="belief distribution of GRAIL against human evil players">
            </div>
          </div>
        </div>
        <!--/ CoT and FT. -->
      </div>
      <p>
        For more results and in depth analyisis, please refer to the paper.
      </p>
    </div>
  </div>
</section>
<!-- Human result -->





<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Demo</h2>
      <!-- <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe> -->
          <iframe  src="https://appapppy-fbwdftiwatu4pxfjvthfsb.streamlit.app/?embedded=true" width="100%" height="850">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
